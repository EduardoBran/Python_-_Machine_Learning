####  Big Data Real-Time Analytics com Python e Spark  ####

# Configurando o diretório de trabalho
setwd("~/Desktop/DataScience/CienciaDeDados/2.Big-Data-Real-Time-Analytics-com-Python-e-Spark/8.Machine_Learning_em_Linguagem_Python")
getwd()



## Importando Pacotes
library(readxl)         # carregar arquivos
library(dplyr)          # manipula dados
library(tidyr)          # manipula dados (funcao pivot_longer)
library(ROSE)           # balanceamento de dados
library(ggplot2)        # gera gráficos
library(patchwork)      # unir gráficos
library(corrplot)       # mapa de correlação

library(caret)          # pacote preProcess para normalização / facilitar a validação cruzada / seleção de hiperparâmetros
library(pROC)           # Para ROC e AUC

library(glmnet)         # algoritmo para regressão logística com regularização
library(randomForest)   # algoritmo de ML




############################  Modelagem Preditiva para Identificação de Risco de Doença Hepática  ############################  

## Etapas:
  
# - Construção, Treinamento, Avaliação e Seleção de Modelos para Classificação

## Introdução:

# - Vamos trabalhar agora em nosso primeiro Mini-Projeto de Machine Learning, cujo objetivo é fornecer um passo a passo completo do processo de construção,
#   treinamento, avaliação e seleção de modelos para classificação. Este projeto será abordado de maneira integral, desde a definição do problema de negócio
#   até as previsões com o modelo treinado.

## Contexto:

# - O número de pacientes com doença hepática tem aumentado continuamente devido a fatores como consumo excessivo de álcool, inalação de gases nocivos,
#   ingestão de alimentos contaminados, e uso de drogas e anabolizantes. Em resposta a essa crescente preocupação de saúde pública, este mini-projeto visa 
#   construir um modelo de Machine Learning capaz de prever se um paciente irá ou não desenvolver uma doença hepática com base em várias características 
#   clínicas e demográficas. Este modelo pode ser extremamente útil para médicos, hospitais ou governos no planejamento de orçamentos de saúde e na criação 
#   de políticas de prevenção eficazes.

## Objetivo:

# - O objetivo é prever uma classe (sim ou não), usaremos aprendizado supervisionado para classificação, criando diferentes versões do modelo com diferentes 
#   algoritmos e passaremos por todo o processo de Machine Learning de ponta a ponta. Usaremos como fonte de dados o dataset disponível no link a seguir.

## Dados:

# Link -> https://archive.ics.uci.edu/ml/datasets/ILPD+(Indian+Liver+Patient+Dataset)

# - Os dados para este projeto são provenientes do "Indian Liver Patient Dataset", disponível no link acima. Este conjunto de dados contém registros de
#   pacientes hepáticos e não hepáticos coletados na Índia. A coluna "Dataset" atua como um rótulo de classe, dividindo os indivíduos em pacientes com doença
#   hepática (1) ou sem a doença (2).



#### Carregando os Dados

df <- data.frame(read.csv2("dados/dataset.csv", sep = ","))

dim(df)
names(df)
head(df)



#### Análise Exploratória

# Tipo de dados
str(df)


## Aplicando Transformações Iniciais

# Converter todas as colunas para numeric, exceto 'Gender' (ficar igual ao código em Python)
df <- df %>%
  mutate(across(-Gender, as.numeric))


# Atualizar valores na coluna 'Dataset' (valor '2' = '0') e renomear para 'Target'
df <- df %>%
mutate(Dataset = if_else(Dataset == 2, 0, Dataset)) %>%
  rename(Target = Dataset)


# Conveter para Factor as Variáveis Gender e Target(variável alvo)
df <- df %>% 
  mutate(Gender = as.factor(Gender),
         Target = as.factor(Target))



## Realizando Análise Inicial (Sumário Estatístico, Veriricação de Valores NA, '' e especiais)

analise_inicial <- function(dataframe_recebido) {
  # Sumário
  cat("\n\n####  DIMENSÕES  ####\n\n")
  print(dim(dataframe_recebido))
  cat("\n\n\n####  INFO  ####\n\n")
  print(str(dataframe_recebido))
  cat("\n\n\n####  SUMÁRIO  ####\n\n")
  print(summary(dataframe_recebido))
  cat("\n\n\n####  VERIFICANDO QTD DE LINHAS DUPLICADAS  ####\n\n")
  print(sum(duplicated(dataframe_recebido)))
  cat("\n\n\n####  VERIFICANDO VALORES NA  ####\n\n")
  valores_na <- colSums(is.na(dataframe_recebido))
  if(any(valores_na > 0)) {
    cat("\n-> Colunas com valores NA:\n\n")
    print(valores_na[valores_na > 0])
  } else {
    cat("\n-> Não foram encontrados valores NA.\n")
  }
  cat("\n\n\n####  VERIFICANDO VALORES VAZIOS ''  ####\n\n")
  valores_vazios <- sapply(dataframe_recebido, function(x) sum(x == "", na.rm = TRUE)) # Adicionando na.rm = TRUE
  if(any(valores_vazios > 0, na.rm = TRUE)) { # Tratamento de NA na condição
    cat("\n-> Colunas com valores vazios \"\":\n\n")
    print(valores_vazios[valores_vazios > 0])
  } else {
    cat("\n-> Não foram encontrados valores vazios \"\".\n")
  }
  cat("\n\n\n####  VERIFICANDO VALORES COM CARACTERES ESPECIAIS  ####\n\n")
  caracteres_especiais <- sapply(dataframe_recebido, function(x) {
    sum(sapply(x, function(y) {
      if(is.character(y) && length(y) == 1) {
        any(charToRaw(y) > 0x7E | charToRaw(y) < 0x20)
      } else {
        FALSE
      }
    }))
  })
  if(any(caracteres_especiais > 0)) {
    cat("\n-> Colunas com caracteres especiais:\n\n")
    print(caracteres_especiais[caracteres_especiais > 0])
  } else {
    cat("\n-> Não foram encontrados caracteres especiais.\n")
  }
}

analise_inicial(df)



## Dividindo dataset em variáveis numéricas e categóricas (para criação de gráficos)
df_num <- df %>% 
  select(where(is.numeric))
df_cat <- df %>% 
  select(where(is.factor))



### Explorando Variáveis Numéricas

# Sumário Estatístico
summary(df_num)


## Visualizando Através de Gráficos

# Converter o dataframe para um formato longo para facilitar a plotagem com ggplot2
df_long <- pivot_longer(df_num, cols = everything())

# Criar histogramas usando ggplot2
ggplot(df_long, aes(x = value)) +
  geom_histogram(bins = 10, fill = "blue", color = "black") +
  facet_wrap(~name, scales = "free") +
  labs(x = "Value", y = "Frequency") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Melhorar a legibilidade dos rótulos do eixo x

rm(df_long)

# Interpretando sumário e gráficos:

# - Parece que há outlier nas variáveis "Alamine_Aminotransferase" e "Aspartate_Aminotransferase", pois o valor máximo é muito mais alto que o valor médio.




### Explorando Variável Categórica

str(df_cat)
summary(df_cat)
plot(df$Gender)
plot(df$Target)

rm(df_num, df_cat)


## Aplicando Label Encoding na Variável 'Gender' e 'Target' (no dataframe original df)

str(df)

# Cria uma Nova Variável 'Gender_Num' onde Male = 0 e Female = 1
# df$Gender_Num <- ifelse(df$Gender == "Male", 0, 1)

# Altera a variável original
df$Gender <- ifelse(df$Gender == "Male", 0, 1)

# Converte fatores para caracteres e depois para numéricos
df$Target <- as.numeric(as.character(df$Target))

str(df)



## Verificando Correlação

#df_num <- df %>% 
#  select(-Gender)
cor(df, use = "complete.obs")

# Criar um mapa de calor da matriz de correlação
corrplot(cor(df, use = "complete.obs"),
         method = "color",
         type = "upper",
         addCoef.col = 'springgreen2',
         tl.col = "black",
         tl.srt = 45)                                     # Esconde a diagonal principal


## Interpretando o resultado da Correlação

# - Vamos citar exemplo:
#   Podemos constatar no dados e gráfico que a variável Total_Bilirubin tem uma alta correlação positiva com a variável Direct_Bilirubin (0.87).
# - Isso é um problema pois a mesma informação está sendo replicada duas vezes e por conta disso pode deixar o modelo tendencioso.
# - O fato de duas variáveis estarem altamente relacionadas (quando tem o valor abaixo ou acima de 0.70) é chamado de Multicolinearidade. 
# - Em algum momento deveremos tomar uma decisão: deixar as duas variáveis, remover uma variável ou remover as duas.

## Atenção

# - Nosso dados ainda não foram limpos/tratados (valores ausentes, replicados ou outliers). É recomendado aplicar algum tipo de tratamento relacionado a Multicolinearidade somente quando os dados estiverem tratados.
# - Estamos na etapa de Análise Exploratória onde estamos entendendo a natureza dos nossos dados.


## Verificando Relação entre Atributos

## Verificando Através de Gráfico a Relação entre as Variáveis 'Direct_Bilirubin' e 'Total_Bilirubin' por 'Target'
ggplot(df, aes(x = Total_Bilirubin, y = Direct_Bilirubin, color = as.factor(Target))) +
  geom_point(alpha = 0.6, size = 3) +  # Pontos semitransparentes e de tamanho moderado
  scale_color_manual(values = c("blue", "red")) +  # Cores para diferentes Targets
  labs(color = "Target") +  # Legenda
  theme_minimal(base_size = 14) +  # Usando um tema minimalista para o background
  theme(
    plot.background = element_rect(fill = "grey90"),  # Cor de fundo do plot
    panel.background = element_rect(fill = "grey90", colour = "grey20", size = 0.5, linetype = "solid"),
    panel.grid.major = element_line(size = 0.5, linetype = 'solid', colour = "grey60"),  # Linhas principais da grade
    panel.grid.minor = element_line(size = 0.25, linetype = 'solid', colour = "grey80")  # Linhas secundárias da grade
  ) +
  labs(title = "Relação entre Total Bilirubin e Direct Bilirubin", x = "Total Bilirubin", y = "Direct Bilirubin")


## Verificando Através de Gráfico a Relação entre as Variáveis 'Direct_Bilirubin' e 'Total_Bilirubin' por 'Gender'
ggplot(df, aes(x = Total_Bilirubin, y = Direct_Bilirubin, color = as.factor(Gender))) +
  geom_point(alpha = 0.6, size = 3) +  # Pontos semitransparentes e de tamanho moderado
  scale_color_manual(values = c("blue", "red")) +  # Cores para diferentes Targets
  labs(color = "Gender") +  # Legenda
  theme_minimal(base_size = 14) +  # Usando um tema minimalista para o background
  theme(
    plot.background = element_rect(fill = "grey90"),  # Cor de fundo do plot
    panel.background = element_rect(fill = "grey90", colour = "grey20", size = 0.5, linetype = "solid"),
    panel.grid.major = element_line(size = 0.5, linetype = 'solid', colour = "grey60"),  # Linhas principais da grade
    panel.grid.minor = element_line(size = 0.25, linetype = 'solid', colour = "grey80")  # Linhas secundárias da grade
  ) +
  labs(title = "Relação entre Total Bilirubin e Direct Bilirubin", x = "Total Bilirubin", y = "Direct Bilirubin")


## Verificando Através de Gráfico a Relação entre as Variáveis 'Albumin' e 'Total_Bilirubin' por 'Target'
ggplot(df, aes(x = Total_Bilirubin, y = Albumin, color = as.factor(Target))) +
  geom_point(alpha = 0.6, size = 3) +  # Pontos semitransparentes e de tamanho moderado
  scale_color_manual(values = c("blue", "red")) +  # Cores para diferentes Targets
  labs(color = "Target") +  # Legenda
  theme_minimal(base_size = 14) +  # Usando um tema minimalista para o background
  theme(
    plot.background = element_rect(fill = "grey90"),  # Cor de fundo do plot
    panel.background = element_rect(fill = "grey90", colour = "grey20", size = 0.5, linetype = "solid"),
    panel.grid.major = element_line(size = 0.5, linetype = 'solid', colour = "grey60"),  # Linhas principais da grade
    panel.grid.minor = element_line(size = 0.25, linetype = 'solid', colour = "grey80")  # Linhas secundárias da grade
  ) +
  labs(title = "Relação entre Total Bilirubin e Albumin", x = "Total Bilirubin", y = "Albumin")


## Verificando Através de Gráfico a Relação entre as Variáveis 'Albumin' e 'Total_Bilirubin' por 'Gender'
ggplot(df, aes(x = Total_Bilirubin, y = Albumin, color = as.factor(Gender))) +
  geom_point(alpha = 0.6, size = 3) +  # Pontos semitransparentes e de tamanho moderado
  scale_color_manual(values = c("blue", "red")) +  # Cores para diferentes Targets
  labs(color = "Gender") +  # Legenda
  theme_minimal(base_size = 14) +  # Usando um tema minimalista para o background
  theme(
    plot.background = element_rect(fill = "grey90"),  # Cor de fundo do plot
    panel.background = element_rect(fill = "grey90", colour = "grey20", size = 0.5, linetype = "solid"),
    panel.grid.major = element_line(size = 0.5, linetype = 'solid', colour = "grey60"),  # Linhas principais da grade
    panel.grid.minor = element_line(size = 0.25, linetype = 'solid', colour = "grey80")  # Linhas secundárias da grade
  ) +
  labs(title = "Relação entre Total Bilirubin e Albumin", x = "Total Bilirubin", y = "Albumin")



#### Conclusões da Análise Exploratória

# - A análise exploratória ajudou a entender a natureza dos dados, preparando o caminho para limpeza de dados e análises mais profundas.
# - Identificou-se a necessidade de tratar valores ausentes e possíveis outliers.
# - A análise de correlação destacou a presença de multicolinearidade, que pode afetar a performance de modelos de aprendizado de máquina.





#### Verfificando e Tratando Valores Ausentes, Replicados e Outliers

analise_inicial(df)


## Verificando Valores Ausentes (o tratamento é aconselhado após tratamento dos valores outliers)

# Exibindo as linhas com valores ausentes
df %>% filter(is.na(Albumin_and_Globulin_Ratio))



## Verificando e Tratando Valores Duplicados

# Exibindo as linhas com valores duplicados
df %>% filter(duplicated(.))

# Removendo linhas duplicadas (remove uma das duplicatas)
df <- df %>% 
  distinct()



## Verificando e Tratando Valores Outliers

# - Irá ser apresentado dois cenários e tomaremos decisões diferentes para cada um deles.


## Cenário 1 (Variável 'Alamine_Aminotransferase')

# Sumário
summary(df$Alamine_Aminotransferase)

# - Através do sumário, podemos observar que a variável possui uma média de 80.14 e um valor máx de 2000. Isso é um sinal de que podemos ter um outlier.
# - Podemos checar esta informação através da criação de um Gráfico BoxPlot.


# Gráfico BoxPLot
ggplot(df, aes(y = Alamine_Aminotransferase)) +
  geom_boxplot(fill = "blue", colour = "black") +
  labs(title = "Boxplot de Alamine Aminotransferase", y = "Alamine Aminotransferase") +
  theme_minimal()  # Aplicando um tema minimalista

# Interpretando o Gráfico

# - Podemos verificar que além do valor de 2000 temos outros diversos valores acima da média (que está próxima de zero).
# - Será que os valores extremos são mesmo outliers para esta variável?
  
# Podemos responder isso verificando contagem de frequência por valor abaixo (filtrando os 5 maiores valores):


# Exibindo os cinco maiores valores únicos e suas frequências:
table(df$Alamine_Aminotransferase)[as.character(sort(unique(df$Alamine_Aminotransferase), decreasing = TRUE)[1:5])]

# Exibindo a quantidade de valores acima da média:
sum(df$Alamine_Aminotransferase > mean(df$Alamine_Aminotransferase))  # Contagem de valores acima da média
length(df$Alamine_Aminotransferase)                                   # Contagem total de valores da variável


# Conclusão

# - Após a análise detalhada da variável 'Alamine_Aminotransferase', identificamos que o valor máximo de 2000 é consideravelmente mais alto que os outros
#   valores próximos, que também são altos mas menos frequentes.
# - Esses valores extremos podem ser considerados outliers devido ao seu afastamento significativo da média e mediana, além de serem raros no dataset,
#   como mostrado pela análise de frequência.

# - Dado esse contexto, é sugerido a avaliação de tratamento desses outliers dentro do cenário de aplicação dos dados. Se estes valores são resultantes de
#   erros de medição ou casos muito atípicos que podem distorcer análises estatísticas, a remoção ou substituição por um limite superior calculado pelo
#   método do IQR é recomendada.
# - Contudo, se esses altos valores representam casos válidos dentro da pesquisa ou aplicação prática dos dados, poderiam ser mantidos, mas com uma análise
#   adicional para confirmar sua validade.

# - Portanto neste caso específico, após verificar a validade dos dados, optou-se por não realizar o tratamento de outliers para esta variável, pois eles
#   representam casos autênticos dentro do contexto estudado.



## Cenário 2 (Variável 'Aspartate_Aminotransferase')

# Sumário
summary(df$Aspartate_Aminotransferase)

# - Através do Sumário podemos observar que a variável possui uma média de 109.89 e um valor máx de 4929. Isso é um sinal de que podemos ter um ou mais
#   valores outlier.
# - Vamos novamente verificar por um Gráfico BoxPlot.

# Gráfico BoxPLot
ggplot(df, aes(y = Aspartate_Aminotransferase)) +
  geom_boxplot(fill = "blue", colour = "black") +
  labs(title = "Boxplot de Aspartate Aminotransferase", y = "Aspartate Aminotransferase") +
  theme_minimal()  # Aplicando um tema minimalista

# Interpretando o gráfico

# - Podemos verificar que novamente temos valores outliers, mas com um comportamente diferente. Parece que temos menos dados com valores extremos.
# - Aqui nós temos apenas dois valores outliers acima de 2000 enquanto todos os outros abaixo deste valor. 
# - E neste caso, todos esses valores extremos são mesmo outliers para esta variável?
  
# Podemos responder isso verificando novamente os maiores valores únicos e suas frequências:


# Exibindo os cinco maiores valores únicos e suas frequências:
table(df$Aspartate_Aminotransferase)[as.character(sort(unique(df$Aspartate_Aminotransferase), decreasing = TRUE)[1:5])]

# Exibindo a quantidade de valores acima da média:
sum(df$Aspartate_Aminotransferase > mean(df$Aspartate_Aminotransferase))  # Contagem de valores acima da média
length(df$Aspartate_Aminotransferase)                                     # Contagem total de valores da variável

# Exibindo a quantidade de valores acima de 2000:
sum(df$Aspartate_Aminotransferase > 2000)                                 # Contagem de valores acima de 2000
length(df$Aspartate_Aminotransferase)                                     # Contagem total de valores da variável


# Conclusão

# - Vamos aplicar um tratamento para limpeza de outlier nesta variável.
# - Iremos manter no dataset todos os registros abaixo do valor 2500 para esta variável.


# Tratando Valores Outliers da Variável 'Alamine_Aminotransferase'

dim(df)
summary(df)

# Aplica tratamento mantendo somente os registros onde o valor for menor ou igual a 3000 e verifica shape
df <- df %>% filter(Aspartate_Aminotransferase <= 3000)
dim(df)

# BoxPlot
ggplot(df, aes(y = Aspartate_Aminotransferase)) +
  geom_boxplot(fill = "blue", colour = "black") +
  labs(title = "Boxplot de Aspartate Aminotransferase Após Primeiro Filtro", y = "Aspartate Aminotransferase")

# Aplica novo tratamento mantendo somente os registros onde o valor for menor ou igual a 2500 e verifica shape 
df <- df %>% filter(Aspartate_Aminotransferase <= 2500)

# BoxPlot
ggplot(df, aes(y = Aspartate_Aminotransferase)) +
  geom_boxplot(fill = "blue", colour = "black") +
  labs(title = "Boxplot de Aspartate Aminotransferase Após Segundo Filtro", y = "Aspartate Aminotransferase")


dim(df)
summary(df)


## Tratando Valores Ausentes
dim(df)

# Removendo todas linhas com valores ausentes
df <- df %>% drop_na()
dim(df)



#### RESUMO

# - Antes de avançarmos para a etapa final de pré-processamento de dados, crucial para a construção de modelos de machine learning, vamos recapitular
#   os passos já concluídos no projeto.:
  
#  -> Primeiro foi definido o problema de negócio para saber o objetivo e o que temos que resolver.
#  -> Depois nós extraímos os dados e nesta etapa pode ser que tenhamos o suporte de um Engenheiro de Dados. No caso deste projeto foi feito a leitura dos
#     dados através de um arquivo csv.
#  -> Na sequência foi feita a Análise Exploratória onde nós verificamos padrões, detectamos problemas, identifica coisas que precisamos fazer.
#  -> Após isso é aplicado a Limpeza de Dados de acordo com as técnicas necessárias, estratégias e decisões.
#  -> Sempre lembrar de documentar tudo o que foi feito em cada atividade.





#### Pré-Processamento de Dados Para Construção de Modelos de Machine Learning

# - Como vimos anteriormente ao aplicarmos o mapa de correlação as variáveis 'Direct_Bilirubin' e 'Total_Bilirubin' possuem uma alta correlação.
# - Com isso foi tomada a decisão de remover umas das variáveis.

# Removendo Variável 'Direct_Bilirubin'
df <- df %>% 
  select(-Direct_Bilirubin)


##  Dividindo os dados em treino e teste
set.seed(100)
indices <- createDataPartition(df$Target, p = 0.75, list = FALSE)
dados_treino <- df[indices, ]
dados_teste <- df[-indices, ]
rm(indices)



## Balanceamento de Classes

# Contagem
table(dados_treino$Target)

# Por que realizar o Balanceamento de Classes ?

# - Como foi observado no table() acima podemos constatar que os dados estão desbalanceados, isso signifca que tem muito mais pacientes de uma classe do
#   que da outra.
# - E o que acontece quando não realizarmos o balanceamento? O modelo de ML aprenderá muito mais o padrão da Classe 1 do que da Classe 0.
# - Caso não aplicamos técnica de Balanceamento, o modelo tende a ficar tendencioso. Por isso precisamos fazer o Balanceamento de Classes.

# Estratégias para o Balanceamento

# Temos duas estratégias:

# - Reduzir os registros da classe majoritária e assim diminuir consideravelmente o número de registros no nosso dataset.
# - Aplicar a técnica de Oversampling onde irá ser aumentado o número de registros das classe minoritária. E como isso é feito? Sendo criado dados
#   sintéticos com base nos dados existentes (Para isso, podemos utilizar o pacote ROSE em R, que oferece funções para gerar dados sintéticos).


# Balanceamento da Variável Alvo (Aplicando a técnica Oversampling para balancear a variável alvo)
table(dados_treino$Target)
dados_balanceados <- ovun.sample(Target ~ ., data = dados_treino, method = "over", N = 2*max(table(dados_treino$Target)))$data
table(dados_balanceados$Target)


# Por que a técnica de oversamping dever se aplicada somente nos dados de treino?

# - A técnica de oversampling deve ser aplicada somente nos dados de treino para evitar o vazamento de dados (data leakage) e garantir uma avaliação justa
#   e realista do modelo durante o teste.
# - Se o balanceamento fosse aplicado ao conjunto de dados completo, incluindo os dados de teste, o modelo poderia acabar sendo avaliado com dados
#   sintéticos, não representativos da realidade, influenciando os resultados dos testes e comprometendo a capacidade de generalização do modelo para novos
#   dados não vistos.
# - Portanto, mantendo o conjunto de teste original, sem dados sintéticos, asseguramos que a performance do modelo reflete melhor sua eficácia em cenários
#   reais.


# Tamanho
dim(dados_treino)
dim(dados_balanceados)

# O dataset de treino agora passou de 423 linhas para 608 linhas.

# Ajusta o nome do dataset de treino
dados_treino <- dados_balanceados
rm(dados_balanceados)

# Contagem
table(dados_treino$Target)



## Padronização x Normalização

# As técnicas de padronização e normalização são usadas no pré-processamento de dados em aprendizado de máquina para preparar variáveis numéricas,
# ajustando suas escalas. Aqui está quando e por que usar cada uma:
  
## Padronização
# Transforma os dados de modo que eles tenham média zero e desvio padrão igual a um.

# - Quando usar    : Aplicável quando os dados já estão centralizados em torno de uma média e precisam de ajuste na escala. É útil em modelos como SVM e
#                    Regressão Logística, que são sensíveis a variações na escala das variáveis de entrada.
# - Exemplo prático: Se medimos altura em centímetros (150-190 cm) e peso em quilogramas (50-100 kg), a padronização permite comparar essas medidas numa 
#                    escala comum, evitando distorções devido a diferentes intervalos de valores.
# - Motivo para
#   este projeto   : Optamos pela padronização porque as variáveis têm escalas muito diferentes e há a presença de outliers significativos. A padronização
#                    mantém as propriedades estatísticas dos dados, minimizando o impacto dos outliers, ao contrário da normalização que pode distorcer os
#                    dados ao comprimir a maioria dos valores em um intervalo estreito.

## Normalização
# Ajusta os dados para que seus valores caibam em um intervalo predefinido, geralmente de 0 a 1.

# - Quando usar    : Ideal para dados com variações extremas nas escalas e onde os algoritmos são sensíveis à magnitude absoluta dos dados, como
#                    K-Nearest Neighbors (KNN) e técnicas de clustering.
# - Exemplo prático: Se um dataset contém preços de produtos variando de R 1𝑎𝑅1000 e quantidades vendidas de 1 a 20 unidades, a normalização faria com
#                    que ambos os atributos tivessem a mesma contribuição no modelo, independentemente da escala original.
# - Motivo para não
#   esta no projeto: Não foi escolhida devido à presença de outliers, que poderiam ser enfatizados indevidamente, e porque a normalização poderia limitar
#                    a eficácia de modelos que assumem uma distribuição normal dos dados.

## Importante:

# - Não é necessário aplicar padronização/normalização na variável alvo.
# - Nós não aplicamos as duas técnicas, ou usamos uma ou outra.
# - A normalização pode não ser a melhor escolha se houver outliers significativos no conjunto de dados, pois isso poderia comprimir a maioria dos dados
#   em um intervalo muito estreito. Nesses casos, a padronização é recomendada.


# Padronizado Dados de Treino
summary(dados_treino)

# Calculando a média e o desvio padrão dos dados de treino 
treino_mean <- sapply(dados_treino[, -which(names(dados_treino) == "Target")], mean, na.rm = TRUE)
treino_std <- sapply(dados_treino[, -which(names(dados_treino) == "Target")], sd, na.rm = TRUE)

# Exibindo a média e o desvio padrão
print(treino_mean)
print(treino_std)

# Padronizando todas as variáveis, exceto 'Target'
dados_treino[, names(treino_mean)] <- sweep(dados_treino[, names(treino_mean)], 2, treino_mean, "-")
dados_treino[, names(treino_std)] <- sweep(dados_treino[, names(treino_std)], 2, treino_std, "/")

summary(dados_treino)


# Padronizado Dados de Teste
summary(dados_teste)

# Padronizando os dados de teste usando a média e desvio padrão dos dados de treino
dados_teste[, names(treino_mean)] <- sweep(dados_teste[, names(treino_mean)], 2, treino_mean, "-")
dados_teste[, names(treino_std)] <- sweep(dados_teste[, names(treino_std)], 2, treino_std, "/")

summary(dados_teste)

rm(treino_mean, treino_std)



#### Construindo Modelos de Machine Learning

# Nesta etapa do projeto, desenvolveremos e avaliaremos cinco diferentes modelos de machine learning para identificar qual deles apresenta o melhor
# desempenho para o nosso conjunto de dados.

# Cada modelo foi escolhido por suas características únicas e capacidade de lidar com problemas de classificação.
# Abaixo estão os modelos que serão implementados e testados:
  
# - Modelo 1: Regressão Logística - Utilizado como benchmark devido à sua simplicidade e eficácia em problemas de classificação binária.
#   Este modelo ajudará a estabelecer uma linha base para a performance que esperamos superar com técnicas mais complexas.

# - Modelo 2: Random Forest - Um modelo de ensemble que usa múltiplas árvores de decisão para melhorar a generalização. É conhecido por sua alta precisão
#   e capacidade de ranquear a importância das variáveis.

# - Modelo 3: KNN (K-Nearest Neighbors) - Um modelo baseado em instância que faz previsões com base nas labels das amostras mais próximas no espaço de
#   características. Este modelo é eficaz em casos onde a relação entre as variáveis é altamente não-linear.

# - Modelo 4: Decision Tree (Árvore de Decisão) - Uma árvore de decisão é útil por sua interpretabilidade, permitindo entender claramente quais critérios
#   o modelo está usando para tomar decisões.

# - Modelo 5: SVM (Support Vector Machine) - Ideal para problemas de classificação e regressão de margem grande. O SVM é eficiente na criação de hiperplanos
#   em um espaço multidimensional, o que o torna adequado para casos com muitas variáveis de entrada.

# Cada modelo será treinado utilizando o mesmo conjunto de dados, permitindo uma comparação justa de sua eficácia. A avaliação de cada modelo incluirá 
# métricas como precisão, AUC-ROC, entre outras, dependendo das especificidades de nosso problema e dados.



## Conversão da Variável Alvo Para Tipo Factor (Certifique-se de que Target é um fator com dois níveis)
dados_treino$Target <- factor(dados_treino$Target, levels = c(0, 1))
dados_teste$Target <- factor(dados_teste$Target, levels = c(0, 1))

# Ajustar os níveis da variável alvo para serem nomes válidos de variáveis em R
levels(dados_treino$Target) <- c("Class0", "Class1")
levels(dados_teste$Target) <- c("Class0", "Class1")


## Cria um dataframe para receber as métricas de cada modelo
df_modelos <- data.frame()



### Modelo 1 com Regressão Logística (Benchmark)

# Para a primeira versão do modelo o ideal é escolher um algoritmo simples, fácil de compreender e que será usado como Benchmark.
# Obs: Como parte do processo envolve aleatoriedade, os resultados podem ser ligeiramente diferentes a cada execução deste bloco de código.


## Versão 1

# - Cria vários modelos utilizando o pacote `caret` com um grid de hiperparâmetros para `glmnet`, que combina standardização de dados e regressão logística
#   com penalidade L2. O objetivo é encontrar os melhores hiperparâmetros.
# - O `GridSearchCV` é simulado no R com a função `train`, aplicando validação cruzada e pré-processamento. Após identificar o melhor parâmetro (lambda),
#   treina-se o modelo final diretamente com a função `glmnet` utilizando os hiperparâmetros otimizados.
# - Isso é feito para assegurar um modelo eficiente e pronto para implementações práticas.


str(dados_treino)
str(dados_teste)


# Definindo o controle de treinamento para Grid Search
train_control <- trainControl(
  method = "cv",
  number = 10,
  savePredictions = "final",
  classProbs = TRUE,
  summaryFunction = twoClassSummary
)

# Define a lista de hiperparâmetros
lambda_grid <- 1 / c(0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000)
tuned_params <- expand.grid(alpha = 0, lambda = lambda_grid)

# Executa o Grid Search usando a fórmula diretamente
grid_search <- train(
  Target ~ .,
  data = dados_treino,
  method = "glmnet",
  tuneGrid = tuned_params,
  trControl = train_control,
  metric = "ROC",
  preProcess = "scale",
  family = "binomial"
)


# Extraindo os melhores parâmetros
best_lambda <- grid_search$bestTune$lambda
best_lambda

# Treinando o modelo final com os melhores parâmetros encontrados
modelo_v1 <- glmnet(
  x = as.matrix(dados_treino[, -which(names(dados_treino) == "Target")]),
  y = as.numeric(dados_treino$Target),
  alpha = 0,  # L2 penalidade como em LogisticRegression com 'l2'
  lambda = best_lambda,
  family = "binomial",
  standardize = TRUE  # Equivalente ao StandardScaler
)
modelo_v1

rm(train_control, lambda_grid, tuned_params, grid_search)


## Previsões

# Preparando dados de teste para previsão
X_teste <- as.matrix(dados_teste[, -which(names(dados_teste) == "Target")])

# Previsões de Classe
y_pred_v1 <- predict(modelo_v1, newx = X_teste, s = "lambda.min", type = "class")
y_pred_v1 <- as.factor(ifelse(y_pred_v1 == "1", "Class0", "Class1"))
head(y_pred_v1)

# Previsões de Probabilidade
y_pred_proba_v1 <- predict(modelo_v1, newx = X_teste, s = "lambda.min", type = "response")
head(y_pred_proba_v1)



## Avaliação do Modelo

# Matriz de Confusão
conf_matrix <- confusionMatrix(y_pred_v1, dados_teste$Target)
conf_matrix

# Calcula e exibe a métrica AUC-ROC
roc_obj <- roc(response = dados_teste$Target, predictor = as.numeric(y_pred_proba_v1))
roc_auc_v1 <- auc(roc_obj)
roc_auc_v1

# Calcula a curva ROC
roc_curve <- roc(response = dados_teste$Target, predictor = as.numeric(y_pred_proba_v1))
roc_curve
plot(roc_curve, main="ROC Curve", col="#1c61b6") # Opcional: Gráfico da curva ROC

# Calcula e exibe a acurácia
acuracia_v1 <- sum(y_pred_v1 == dados_teste$Target) / length(y_pred_v1)
acuracia_v1

# Exibindo os resultados
cat("Confusion Matrix:\n")
print(conf_matrix$table)
cat(sprintf("\nAUC-ROC: %f\n", roc_auc_v1))
cat(sprintf("Accuracy: %f\n", acuracia_v1))


## Salvando as métricas do modelo_v1 em um Dicionário
dict_modelo_v1 <- data.frame(
  Nome = "modelo_v1",
  Algoritmo = "Regressão Logística",
  ROC_AUC_Score = as.numeric(roc_auc_v1),  # Converte AUC para numérico
  AUC_Score = as.numeric(auc(roc_curve)),  # AUC calculada da curva ROC, também convertida
  Acuracia = acuracia_v1
)

## Adiciona o Dicionário com resultado das métricas do modelo_v1 no dataframe com resultados
df_modelos <- bind_rows(df_modelos, dict_modelo_v1)
df_modelos

rm(X_teste, y_pred_v1, y_pred_proba_v1, conf_matrix, roc_obj, acuracia_v1, roc_auc_v1, roc_curve, dict_modelo_v1)



## Versão 2

# - Aplica a Técnica de Feature Selection no modelo_v1 criado na Versão 1
# - Re-cria o modelo utilizando as 5 variáveis mais importantes


# Extraindo coeficientes do modelo para o melhor lambda
coeficientes <- as.matrix(coef(modelo_v1, s = best_lambda))
rownames(coeficientes) <- c("(Intercept)", names(dados_treino)[-which(names(dados_treino) == "Target")])

# Calculando a importância como o valor absoluto dos coeficientes
importancias <- abs(coeficientes[-1, , drop = FALSE])  # Exclui o intercepto
df_importancias <- data.frame(
  Feature = rownames(importancias),
  Importance = importancias[, 1]
)
df_importancias <- df_importancias[order(-df_importancias$Importance), ]

# Visualizando por Números
print(df_importancias)

# Visualiando por Gráfico
ggplot(df_importancias, aes(x = Importance, y = reorder(Feature, Importance))) +
  geom_bar(stat = "identity", fill = "skyblue", orientation = "y") +
  labs(title = "Importância das Variáveis", x = "Importância", y = "Variável") +
  theme_minimal() +
  theme(axis.text.y = element_text(angle = 0, hjust = 1))  # Melhorando a legibilidade dos rótulos


## Selecionando as 5 variáveis mais importantes
vars_importantes <- head(df_importancias$Feature, 5)


## Recriando o modelo usando apenas as variáveis mais importantes
dados_treino_importantes <- dados_treino[, c(vars_importantes, "Target")]

# Recriando modelo_v2 com variáveis selecionadas
modelo_v2 <- glmnet(
  x = as.matrix(dados_treino_importantes[, -which(names(dados_treino_importantes) == "Target")]),
  y = as.numeric(dados_treino_importantes$Target),
  alpha = 0,  # L2 penalidade como em LogisticRegression com 'l2'
  lambda = best_lambda,
  family = "binomial",
  standardize = TRUE
)
modelo_v2


## Preparando dados de teste para previsão com as variáveis mais importantes
dados_teste_importantes <- dados_teste[, c(vars_importantes, "Target")]
X_teste_importantes <- as.matrix(dados_teste_importantes[, -which(names(dados_teste_importantes) == "Target")])


## Previsões de Classe
y_pred_v2 <- predict(modelo_v2, newx = X_teste_importantes, s = "lambda.min", type = "class")
y_pred_v2 <- as.factor(ifelse(y_pred_v2 == "1", "Class0", "Class1"))

# Previsões de Probabilidade
y_pred_proba_v2 <- predict(modelo_v2, newx = X_teste_importantes, s = "lambda.min", type = "response")


## Avaliação do Modelo
conf_matrix_v2 <- confusionMatrix(y_pred_v2, dados_teste_importantes$Target)
roc_obj_v2 <- roc(response = dados_teste_importantes$Target, predictor = as.numeric(y_pred_proba_v2))
roc_auc_v2 <- auc(roc_obj_v2)
acuracia_v2 <- sum(y_pred_v2 == dados_teste_importantes$Target) / length(y_pred_v2)

# Salvando as métricas do modelo_v2 em um Dicionário
dict_modelo_v2 <- data.frame(
  Nome = "modelo_v2",
  Algoritmo = "Regressão Logística com Seleção de Variáveis",
  ROC_AUC_Score = as.numeric(roc_auc_v2),
  AUC_Score = as.numeric(auc(roc_obj_v2)),
  Acuracia = acuracia_v2
)

# Adiciona o Dicionário com resultado das métricas do modelo_v2 no dataframe com resultados
df_modelos <- bind_rows(df_modelos, dict_modelo_v2)
df_modelos

rm(modelo_v1, modelo_v2, dados_teste_importantes, X_teste_importantes, importancias, y_pred_v2, y_pred_proba_v2, conf_matrix_v2, roc_obj_v2,
   roc_auc_v2, acuracia_v2, dict_modelo_v2, best_lambda, coeficientes, df_importancias, vars_importantes, dados_treino_importantes)




###  Modelo 2 com Random Forest

# Nosso desafio agora é tentar obter um modelo melhor que a versão 1. Vamos tentar o algoritmo Random Forest.


## Versão 1

# - 





#### Visualizando os Resultados em um Dataframe

df_modelos















#### Separando Dados de Treino e Teste (Python X R)

## No R:
# - É comum especificar a variável alvo diretamente nos modelos ou funções de treinamento. Por exemplo, ao usar o pacote caret ou funções nativas como lm()
#   para regressão linear, você normalmente formula o modelo dentro da função, como em lm(y ~ ., data = dados_treino), onde y é a variável alvo e
#   indica o uso de todas as outras variáveis no dataframe como preditores.
# - Isso significa que não há necessidade estrita de separar fisicamente a variável alvo das demais variáveis antes do treinamento do modelo.

## No Python:
# - Ao usar bibliotecas como scikit-learn, você geralmente precisa passar explicitamente os arrays ou matrizes de características e a variável alvo
#   separadamente para as funções de treinamento. Por exemplo, ao treinar um regressor logístico, você usaria algo como LogisticRegression().fit(X_treino,
#   y_treino). Aqui, X_treino e y_treino são passados como argumentos separados, o que requer que você prepare esses objetos com antecedência.
# - Em Python, mesmo que você esteja usando uma biblioteca que permite formulações mais semelhantes ao R (como statsmodels), a prática comum e a maioria
#   das APIs de machine learning ainda segue o padrão de passar X e y separadamente.

# Por que isso é feito dessa forma em Python?

# - A separação explícita de X e y fornece clareza e evita erros em um ecossistema que é menos integrado do que o R para análises estatísticas.
#   As bibliotecas de Python, como scikit-learn, são projetadas para serem agnósticas quanto ao tipo de dados, permitindo o trabalho com arrays numpy,
#   dataframes pandas, e outros formatos de dados, de uma maneira altamente modular e flexível. Além disso, essa separação ajuda na implementação de uma
#   variedade de pré-processamentos e transformações de maneira mais controlada e sem risco de alterar inadvertidamente a variável alvo.

# Essas diferenças refletem filosofias de design distintas e têm implicações práticas na maneira como você prepara e manipula dados para análises e
# modelagem em cada linguagem.

    
